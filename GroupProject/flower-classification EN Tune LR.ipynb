{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1c62db",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 1.406695,
     "end_time": "2024-04-07T12:58:23.373024",
     "exception": false,
     "start_time": "2024-04-07T12:58:21.966329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3491224c-3d18-4dff-a824-6412a44f2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b8a140",
   "metadata": {
    "papermill": {
     "duration": 28.390516,
     "end_time": "2024-04-07T12:58:51.769186",
     "exception": false,
     "start_time": "2024-04-07T12:58:23.378670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torchvision.transforms import Compose, Lambda, ToTensor, Normalize, Resize, RandomCrop, TenCrop, RandomHorizontalFlip\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47b41fe9",
   "metadata": {
    "papermill": {
     "duration": 0.09495,
     "end_time": "2024-04-07T12:58:51.869712",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.774762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some settings:\n",
    "# --------------\n",
    "train_files = '/home/msai/mkee004/AI6102/extracted_contents/tfrecords-jpeg-224x224/train/*.tfrec'\n",
    "valid_files = '/home/msai/mkee004/AI6102/extracted_contents/tfrecords-jpeg-224x224/val/*.tfrec'\n",
    "test_files  = '/home/msai/mkee004/AI6102/extracted_contents/tfrecords-jpeg-224x224/test/*.tfrec'\n",
    "device      = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "wdn_epochs    = 20  \n",
    "lrn_epochs    = 20 \n",
    "batch_size  = 20                                                           \n",
    "num_prints  = 10                                                            \n",
    "train_size  = 12753                                                        \n",
    "print_freq  = train_size // (batch_size * num_prints) + 1                  \n",
    "check_freq  = 1                                                            \n",
    "n_classes = 104\n",
    "base_lr = 3e-4\n",
    "classifier_lr = 3e-3\n",
    "weight_decay = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5cd1a72",
   "metadata": {
    "papermill": {
     "duration": 0.016752,
     "end_time": "2024-04-07T12:58:51.891957",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.875205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert to df\n",
    "def tfrecords_to_dataframe(fp, test = False):\n",
    "\n",
    "    def parse(pb, test = False):\n",
    "        d = {'id': tf.io.FixedLenFeature([], tf.string), 'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "        if not test:\n",
    "            d['class'] = tf.io.FixedLenFeature([], tf.int64)\n",
    "        return tf.io.parse_single_example(pb, d)\n",
    "\n",
    "    df = {'id': [], 'img': []} \n",
    "    if not test:\n",
    "        df['lab'] = []\n",
    "    for sample in tf.data.TFRecordDataset(glob.glob(fp)).map(lambda pb: parse(pb, test)):\n",
    "        df['id'].append(sample['id'].numpy().decode('utf-8'))\n",
    "        df['img'].append(sample['image'].numpy())\n",
    "        if not test:\n",
    "            df['lab'].append(sample['class'].numpy())\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecd315e6",
   "metadata": {
    "papermill": {
     "duration": 0.013803,
     "end_time": "2024-04-07T12:58:51.910953",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.897150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def display_images(dataset, n, cols):\n",
    "    rows = n // cols if n % cols == 0 else n // cols + 1\n",
    "    plt.figure(figsize = (2 * cols, 2 * rows))\n",
    "    for i in range(n):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        img, lab = dataset[i]\n",
    "        plt.imshow(img.permute(1, 2, 0).numpy())\n",
    "        plt.title(str(lab))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85a8092f",
   "metadata": {
    "papermill": {
     "duration": 0.015483,
     "end_time": "2024-04-07T12:58:51.931845",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.916362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainset(Dataset):\n",
    "    def __init__(self, frac=1):\n",
    "        super().__init__()\n",
    "        self.df = tfrecords_to_dataframe(train_files).sample(frac=frac).reset_index(drop=True)\n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.Lambda(lambda b: transforms.ToTensor()(Image.open(io.BytesIO(b)))),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            Resize(np.random.randint(300, 641)),\n",
    "            transforms.RandomCrop(300),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #transform = Compose(Resize(np.random.randint(300, 641)))\n",
    "        img = self.transforms(self.df.iloc[idx]['img'])\n",
    "        return img, self.df.iloc[idx]['lab']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240c301f",
   "metadata": {
    "papermill": {
     "duration": 0.016575,
     "end_time": "2024-04-07T12:58:51.953680",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.937105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evalset(Dataset):\n",
    "    def __init__(self, frac=1, test=False):\n",
    "        super().__init__()\n",
    "        files = valid_files if not test else test_files\n",
    "        self.df = tfrecords_to_dataframe(files, test).sample(frac=frac,random_state=0).reset_index(drop=True)\n",
    "        self.transforms = [Compose([\n",
    "            Lambda(lambda b: Image.open(io.BytesIO(b))),\n",
    "            Resize(scale),\n",
    "            TenCrop(300),\n",
    "            Lambda(lambda xs: torch.stack([ToTensor()(x) for x in xs])),\n",
    "            Lambda(lambda xs: torch.stack([Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])(x) for x in xs]))\n",
    "        ]) for scale in [372, 568]]\n",
    "        self.test = test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        sample = self.df.iloc[i]\n",
    "        imgs = torch.stack([t(sample['img']) for t in self.transforms])\n",
    "        return imgs, sample['lab'] if not self.test else sample['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8ccb8db",
   "metadata": {
    "papermill": {
     "duration": 0.01422,
     "end_time": "2024-04-07T12:58:51.973089",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.958869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EfficientNetB0(nn.Module):\n",
    "    def __init__(self, n_classes, learnable_modules=('classifier.1',)):\n",
    "        super().__init__()\n",
    "        self.efficientnet_b0 = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet_b0.classifier[1] = nn.Linear(self.efficientnet_b0.classifier[1].in_features, n_classes)\n",
    "        self.efficientnet_b0.requires_grad_(False)\n",
    "        \n",
    "        modules = dict(self.efficientnet_b0.named_modules())\n",
    "        for name in learnable_modules:\n",
    "            if name in modules:\n",
    "                modules[name].requires_grad_(True)\n",
    "            else:\n",
    "                raise ValueError(f\"Module name '{name}' not found in the model's named modules.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.efficientnet_b0(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930f8e21",
   "metadata": {
    "papermill": {
     "duration": 19.727715,
     "end_time": "2024-04-07T12:59:11.706029",
     "exception": false,
     "start_time": "2024-04-07T12:58:51.978314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 19:02:01.850080: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-04-25 19:02:04.025420: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "# valid_loader = DataLoader(Evalset(frac = 0.20), batch_size = 1, num_workers = 2)\n",
    "# test_loader  = DataLoader(Evalset(test = True), batch_size = 1, num_workers = 2)\n",
    "\n",
    "train_loader = DataLoader(Trainset(frac=1), batch_size = batch_size, shuffle = True, num_workers = 0)\n",
    "valid_loader = DataLoader(Evalset(frac = 0.20), batch_size = 1, num_workers = 0)\n",
    "#test_loader  = DataLoader(Evalset(test = True,frac=0.1), batch_size = 1, num_workers = 0)\n",
    "\n",
    "\n",
    "# Display some training images and labels:\n",
    "# ----------------------------------------\n",
    "#display_images(train_set, n = 30, cols = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564dc477-3cd8-4577-b9c4-8aa7dca00250",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DataLoader(Evalset(frac = 0.20), batch_size = 1, num_workers = 0)\n",
    "len(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dce1f6-f764-4f23-88d8-7dd1d619737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ec3512b",
   "metadata": {
    "papermill": {
     "duration": 0.544386,
     "end_time": "2024-04-07T12:59:12.266051",
     "exception": false,
     "start_time": "2024-04-07T12:59:11.721665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/msai/mkee004/.conda/envs/rmenv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/msai/mkee004/.conda/envs/rmenv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial learning rate: 0.0003, Classifier learning rate: 0.003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnable_modules = ('features.5.2', 'features.6', 'features.7', 'features.8', 'classifier')\n",
    "\n",
    "# Model Initialization\n",
    "model = nn.DataParallel(EfficientNetB0(n_classes=n_classes, learnable_modules=learnable_modules))\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer Setup\n",
    "param_groups = [\n",
    "    {'params': model.module.efficientnet_b0.features[5][2].parameters()},\n",
    "    {'params': model.module.efficientnet_b0.features[6].parameters()},\n",
    "    {'params': model.module.efficientnet_b0.features[7].parameters()},\n",
    "    {'params': model.module.efficientnet_b0.features[8].parameters()},\n",
    "    {'params': model.module.efficientnet_b0.classifier.parameters(), 'lr': classifier_lr}\n",
    "]\n",
    "optimizer = torch.optim.Adam(params=param_groups, lr=base_lr, weight_decay=weight_decay)\n",
    "\n",
    "# Scheduler Setup\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=wdn_epochs)\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = F.nll_loss\n",
    "\n",
    "# Log the initial learning rate\n",
    "print(f\"Initial learning rate: {base_lr}, Classifier learning rate: {classifier_lr}\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce10d380",
   "metadata": {
    "papermill": {
     "duration": 3147.63959,
     "end_time": "2024-04-07T13:51:39.922756",
     "exception": false,
     "start_time": "2024-04-07T12:59:12.283166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "--------------------\n",
      "Batch 0, Loss: 4.6860\n",
      "Batch 64, Loss: 2.3732\n",
      "Batch 128, Loss: 1.3690\n",
      "Batch 192, Loss: 1.6659\n",
      "Batch 256, Loss: 1.5676\n",
      "Batch 320, Loss: 1.0563\n",
      "Batch 384, Loss: 1.3275\n",
      "Batch 448, Loss: 1.5218\n",
      "Batch 512, Loss: 0.9313\n",
      "Batch 576, Loss: 1.6595\n",
      "Training Loss: 1.7098\n",
      "Validation F1: 64.88%, Validation Loss: 1.4351\n",
      "\n",
      "Epoch 2/20\n",
      "--------------------\n",
      "Batch 0, Loss: 1.4794\n",
      "Batch 64, Loss: 0.9290\n",
      "Batch 128, Loss: 0.6989\n",
      "Batch 192, Loss: 1.4272\n",
      "Batch 256, Loss: 0.8423\n",
      "Batch 320, Loss: 0.6523\n",
      "Batch 384, Loss: 1.4904\n",
      "Batch 448, Loss: 0.7298\n",
      "Batch 512, Loss: 0.7715\n",
      "Batch 576, Loss: 1.4810\n",
      "Training Loss: 0.9530\n",
      "Validation F1: 70.13%, Validation Loss: 1.1755\n",
      "1\n",
      "\n",
      "Epoch 3/20\n",
      "--------------------\n",
      "Batch 0, Loss: 0.5060\n",
      "Batch 64, Loss: 0.6908\n",
      "Batch 128, Loss: 1.2330\n",
      "Batch 192, Loss: 1.2840\n",
      "Batch 256, Loss: 1.2593\n",
      "Batch 320, Loss: 0.6910\n",
      "Batch 384, Loss: 0.6906\n",
      "Batch 448, Loss: 0.4213\n",
      "Batch 512, Loss: 0.6275\n",
      "Batch 576, Loss: 0.6786\n",
      "Training Loss: 0.7763\n",
      "Validation F1: 73.30%, Validation Loss: 1.1850\n",
      "2\n",
      "\n",
      "Epoch 4/20\n",
      "--------------------\n",
      "Batch 0, Loss: 0.6375\n",
      "Batch 64, Loss: 0.6767\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "\n",
    "losses = []\n",
    "valid_f1s = []\n",
    "valid_losses = []\n",
    "max_f1=0\n",
    "last_loss_state = 1\n",
    "name='ENLR3e_420Epochsv2'\n",
    "# Initialize a file to store training and validation losses and accuracies\n",
    "log_filename = f'{name}_Log.txt'\n",
    "with open(log_filename, 'a') as log_file:\n",
    "    log_file.write(f'\\n{log_filename}\\n')\n",
    "    log_file.write(f'--------------- \\n')\n",
    "\n",
    "epoch_start_time = time.time()\n",
    "\n",
    "for epoch in range(lrn_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{lrn_epochs}\")\n",
    "    print('-' * 20)\n",
    "    with open(log_filename, 'a') as log_file:\n",
    "        log_file.write(f'\\n{name} Epoch {epoch + 1}/{lrn_epochs} \\n')\n",
    "        log_file.write(f'--------------- \\n')\n",
    "\n",
    "    # Training phase\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)  # Move inputs to the appropriate device\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(x)  # Forward pass\n",
    "        loss = loss_fn(outputs, y)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Optimize\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)  # Update running loss\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n",
    "            with open(log_filename, 'a') as log_file:\n",
    "                log_file.write(f'Batch {i}, Loss: {loss.item():.4f} \\n')\n",
    "            \n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)  # Calculate average loss for the epoch\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}\")\n",
    "    with open(log_filename, 'a') as log_file:\n",
    "        log_file.write(f'Training Loss: {epoch_loss:.4f} \\n')\n",
    "\n",
    "    # Validation phase\n",
    "    if epoch % check_freq == 0:\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        running_val_loss = 0.0\n",
    "\n",
    "        valid_true_labs = []\n",
    "        valid_pred_labs = []\n",
    "        \n",
    "        with torch.no_grad():  # Disables gradient calculation\n",
    "            for x, y in valid_loader:\n",
    "                # Assuming the extra dimensions are not needed, and you want to use one of the \"sub-batches\"\n",
    "                # Adjust the slicing based on which part of the data you need\n",
    "                x_corrected = x[:, 0, 0, :, :, :]  # This takes the first \"sub-batch\" and removes extra dimensions\n",
    "                x_corrected = x_corrected.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                # Now x_corrected should have the shape [1, 3, 300, 300] or similar (adjust based on your needs)\n",
    "                outputs = model(x_corrected)\n",
    "                loss = loss_fn(outputs, y)\n",
    "                running_val_loss += loss.item() * x.size(0)\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                valid_true_labs.extend(y.tolist())\n",
    "                valid_pred_labs.extend(preds.tolist())\n",
    "\n",
    "        epoch_val_loss = running_val_loss / len(valid_loader.dataset)\n",
    "        valid_losses.append(epoch_val_loss)\n",
    "        valid_f1 = f1_score(valid_true_labs, valid_pred_labs, average='weighted')\n",
    "        valid_f1s.append(valid_f1)\n",
    "        print(f\"Validation F1: {valid_f1 * 100:.2f}%, Validation Loss: {epoch_val_loss:.4f}\")\n",
    "        with open(log_filename, 'a') as log_file:\n",
    "            log_file.write(f'Validation F1: {valid_f1 * 100:.2f}% \\n')\n",
    "            log_file.write(f'Validation Loss: {epoch_val_loss:.4f} \\n')\n",
    "\n",
    "        # # Save model checkpoint\n",
    "        # torch.save(model.state_dict(), f'./model/{name}_epoch{epoch // check_freq}.pth')\n",
    "\n",
    "        # Save model checkpoint\n",
    "        if epoch_loss < last_loss_state:\n",
    "            last_loss_state = epoch_loss\n",
    "            best_epoch = epoch\n",
    "            print(best_epoch)\n",
    "            if epoch % check_freq == 0:\n",
    "                torch.save(model.state_dict(), f'./{name}Tune{epoch // check_freq}.pth')\n",
    "\n",
    "    # Adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "epoch_end_time = time.time()\n",
    "epoch_duration = epoch_end_time - epoch_start_time\n",
    "total_duration = epoch_duration / 60  # Convert to minutes\n",
    "print(f'Total duration: {total_duration} minutes \\n')\n",
    "with open(log_filename, 'a') as log_file:\n",
    "    log_file.write(f'Total duration: {total_duration} minutes \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf75192-0486-46b5-b351-5769c29cf7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNetB0withDropOut(nn.Module):\n",
    "    def __init__(self, n_classes, learnable_modules=('classifier.1',), dropout_p=0.15):\n",
    "        super().__init__()\n",
    "        self.efficientnet_b0 = models.efficientnet_b0(pretrained=True)\n",
    "        self.efficientnet_b0.classifier[1] = nn.Linear(self.efficientnet_b0.classifier[1].in_features, n_classes)\n",
    "        self.efficientnet_b0.requires_grad_(False)\n",
    "        \n",
    "        modules = dict(self.efficientnet_b0.named_modules())\n",
    "        for name in learnable_modules:\n",
    "            if name in modules:\n",
    "                modules[name].requires_grad_(True)\n",
    "            else:\n",
    "                raise ValueError(f\"Module name '{name}' not found in the model's named modules.\")\n",
    "        \n",
    "        # Adding dropout layer with specified dropout probability\n",
    "        self.dropout = nn.Dropout(p=dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Applying dropout before the classifier\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(self.efficientnet_b0(x), dim=1)\n",
    "\n",
    "modeldropout = nn.DataParallel(EfficientNetB0withDropOut(n_classes = 104, learnable_modules = ('features.5.2', \n",
    "                                                                             'features.6', \n",
    "                                                                             'features.7', \n",
    "                                                                             'features.8', \n",
    "                                                                             'classifier')))\n",
    "modeldropout.to(device)\n",
    "\n",
    "optimizerdropout = torch.optim.Adam(params = [{'params': modeldropout.module.efficientnet_b0.features[5][2].parameters()}, \n",
    "                                       {'params': modeldropout.module.efficientnet_b0.features[6].parameters()}, \n",
    "                                       {'params': modeldropout.module.efficientnet_b0.features[7].parameters()},\n",
    "                                       {'params': modeldropout.module.efficientnet_b0.features[8].parameters()},\n",
    "                                       {'params': modeldropout.module.efficientnet_b0.classifier.parameters(), 'lr': 1e-3}], \n",
    "                             lr = learningRate, \n",
    "                             weight_decay = weightDecay)\n",
    "\n",
    "schedulerdropout = CosineAnnealingLR(optimizerdropout, T_max = n_epochs)\n",
    "\n",
    "losses = []\n",
    "valid_f1s = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{n_epochs}\")\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Training phase\n",
    "    modeldropout.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)  # Move inputs to the appropriate device\n",
    "\n",
    "        optimizerdropout.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = modeldropout(x)  # Forward pass\n",
    "        loss = loss_fn(outputs, y)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizerdropout.step()  # Optimize\n",
    "\n",
    "        running_loss += loss.item() * x.size(0)  # Update running loss\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)  # Calculate average loss for the epoch\n",
    "    losses.append(epoch_loss)\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Validation phase\n",
    "    if epoch % check_freq == 0:\n",
    "        modeldropout.eval()  # Set model to evaluation mode\n",
    "        valid_true_labs = []\n",
    "        valid_pred_labs = []\n",
    "        \n",
    "        with torch.no_grad():  # Disables gradient calculation\n",
    "            for x, y in valid_loader:\n",
    "                # Assuming the extra dimensions are not needed, and you want to use one of the \"sub-batches\"\n",
    "                # Adjust the slicing based on which part of the data you need\n",
    "                x_corrected = x[:, 0, 0, :, :, :]  # This takes the first \"sub-batch\" and removes extra dimensions\n",
    "                x_corrected = x_corrected.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                # Now x_corrected should have the shape [1, 3, 300, 300] or similar (adjust based on your needs)\n",
    "                outputs = modeldropout(x_corrected)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "                valid_true_labs.extend(y.tolist())\n",
    "                valid_pred_labs.extend(preds.tolist())\n",
    "\n",
    "        valid_f1 = f1_score(valid_true_labs, valid_pred_labs, average='weighted')\n",
    "        valid_f1s.append(valid_f1)\n",
    "        print(f\"Validation F1: {valid_f1 * 100:.2f}%\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        torch.save(modeldropout.state_dict(), f'./epochdropout{epoch // check_freq}.pth')\n",
    "\n",
    "    # Adjust learning rate\n",
    "    schedulerdropout.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da922722",
   "metadata": {
    "papermill": {
     "duration": 0.949859,
     "end_time": "2024-04-07T13:51:40.912466",
     "exception": false,
     "start_time": "2024-04-07T13:51:39.962607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = np.random.normal(loc=0.5, scale=0.1, size=n_epochs * 10)  # Example losses\n",
    "valid_f1s = np.linspace(0.5, 0.9, n_epochs // check_freq)  # Example F1 scores\n",
    "optimal_epoch = np.argmax(np.array(valid_f1s))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# Plot for Training Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(len(losses)) / (len(losses) / n_epochs), losses, color='tab:blue', linewidth=2, label='Training Loss')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Loss Over Epochs', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend()\n",
    "\n",
    "# Plot for Validation F1 Score\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(np.arange(len(valid_f1s)) * check_freq, valid_f1s, color='tab:green', linewidth=2, label='Validation F1')\n",
    "ax2.vlines(optimal_epoch * check_freq, 0, valid_f1s[optimal_epoch], colors='red', linestyles='dashed', label=f'Optimal Epoch ({optimal_epoch * check_freq})')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Weighted F1 Score', fontsize=12)\n",
    "ax2.set_title('Validation F1 Score Over Epochs', fontsize=14)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "ax2.legend()\n",
    "\n",
    "# Saving and showing the improved plot\n",
    "plt.savefig('improved_plot.png')  # Adjust path as needed\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa3d30",
   "metadata": {
    "papermill": {
     "duration": 991.576559,
     "end_time": "2024-04-07T14:08:12.526262",
     "exception": false,
     "start_time": "2024-04-07T13:51:40.949703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        ids.append(y[0])\n",
    "        mean_logp = model(x.view(-1, 3, 300, 300).to(device)).mean(dim = 0)\n",
    "        preds.append(torch.argmax(mean_logp).item())\n",
    "submission = pd.DataFrame({'id': ids, 'label': preds})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959b77b0",
   "metadata": {
    "papermill": {
     "duration": 0.062528,
     "end_time": "2024-04-07T14:08:12.626053",
     "exception": false,
     "start_time": "2024-04-07T14:08:12.563525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467d271",
   "metadata": {
    "papermill": {
     "duration": 0.055415,
     "end_time": "2024-04-07T14:08:12.719214",
     "exception": false,
     "start_time": "2024-04-07T14:08:12.663799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 1243559,
     "sourceId": 21154,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "rmenv",
   "language": "python",
   "name": "rmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4197.826796,
   "end_time": "2024-04-07T14:08:15.889818",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-07T12:58:18.063022",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
